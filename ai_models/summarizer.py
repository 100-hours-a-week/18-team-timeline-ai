import re
import json
import time
from typing import TypedDict, List, Tuple
from textwrap import dedent
from langchain.chat_models import ChatOpenAI
from langchain.schema import BaseOutputParser
from langchain.prompts import ChatPromptTemplate
from langgraph.graph import StateGraph, END, START
from concurrent.futures import ThreadPoolExecutor, as_completed
from langchain_core.messages import AIMessage, HumanMessage
from newspaper import Article
from langchain.globals import set_debug, get_debug
from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate


class ArticleExtractor:
    """ê¸°ì‚¬ URLìœ¼ë¡œë¶€í„° ë³¸ë¬¸ì„ ì¶”ì¶œí•˜ëŠ” í´ë˜ìŠ¤"""

    @staticmethod
    def extract(urls: list[str], max_workers: int = 6) -> list[Tuple[str, str]]:
        """ê¸°ì‚¬ì˜ URL ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ë³¸ë¬¸ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
        Args:
            URLs (list[str]): ê¸°ì‚¬ ë§í¬ë“¤ì˜ ë¦¬ìŠ¤íŠ¸
            max_workers (int): ë™ì‹œì— ì‘ì—…í•  ìŠ¤ë ˆë“œ ìˆ˜ (ê¸°ë³¸ê°’ 6)

        Returns:
            list[str]: ê° ê¸°ì‚¬ ë³¸ë¬¸ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ ("NOT"ì€ ì œì™¸)
        """

        def _extract_single(url: str) -> Tuple[str, str]:
            try:
                article = Article(url=url, language="ko")
                article.download()
                article.parse()
                text = article.text.strip()
                if text and text != "NOT":
                    return text
                else:
                    return None
            except Exception as e:
                print(f"âš ï¸ Error while extracting {url}: {e}")
                return None

        texts = []
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {executor.submit(_extract_single, url): url for url in urls}
            for future in as_completed(futures):
                url = futures[future]  # âœ… ì–´ë–¤ urlì— ëŒ€í•œ futureì˜€ëŠ”ì§€ êº¼ëƒ„
                text = future.result()
                if text:
                    texts.append((url, text))  # âœ… (url, text) í˜•íƒœë¡œ ì¶”ê°€

        return texts


class GraphState(TypedDict):
    input_text: str
    summary: str
    score: int
    worker_id: int
    retry_count: int
    status: str


class SummaryScoreParser(BaseOutputParser):
    def parse(self, text: str):
        cleaned = re.sub(r"^```json\s*|\s*```$", "", text.strip(), flags=re.MULTILINE)
        try:
            return json.loads(cleaned)
        except json.JSONDecodeError as e:
            print(f"âš ï¸ JSONDecodeError: {e} â†’ fallback ì‹œë„")
            # ì½¤ë§ˆ ëˆ„ë½ì´ë‚˜ ì‚¬ì†Œí•œ ì˜¤ë¥˜ë¥¼ ê°„ë‹¨íˆ ë³µêµ¬ ì‹œë„
            cleaned = cleaned.replace('}"', '", "').replace("}{", "},{")
            return json.loads(cleaned)


class SummarizationGraph:
    """Summarization + Evaluation + Retry Graph ìƒì„±ê¸°"""

    def __init__(self, server, model, examples: list, max_retries: int = 3):
        self.llm = ChatOpenAI(
            base_url=f"{server}/v1",
            api_key="not-needed",
            model=model,
            temperature=0.3,
        )
        self.examples = examples
        self.max_retries = max_retries

    def summarize_node(self, state: GraphState) -> GraphState:
        """ğŸ“ ë‰´ìŠ¤ ìš”ì•½ ë…¸ë“œ"""
        system_prompt = """
        ë‹¹ì‹ ì€ ë‰´ìŠ¤ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        - 3ì¤„ ì´ë‚´, ì™„ê²°ëœ ë¬¸ì¥, í•µì‹¬ ì‚¬ì‹¤ë§Œ ìš”ì•½í•˜ì„¸ìš”.
        - ì˜ˆì¸¡, í•´ì„, ì‚¬ê²¬ì€ ê¸ˆì§€í•©ë‹ˆë‹¤.
        """
        prompt = ChatPromptTemplate.from_messages(
            [("system", system_prompt), *self.examples, ("human", "{input_text}")]
        )
        runnable = prompt | self.llm
        result = runnable.invoke({"input_text": state["input_text"]})

        retry_count = state.get("retry_count", 0)
        return {"summary": result.content, "retry_count": retry_count}

    def evaluate_node(self, state: GraphState) -> GraphState:
        """ğŸ“Š ìš”ì•½ í‰ê°€ ë…¸ë“œ"""
        eval_prompt = ChatPromptTemplate(
                messages=[
                    SystemMessagePromptTemplate.from_template(
                        """
                        You are a strict JSON evaluator for news summaries.
                        Respond ONLY with JSON object: \'{{\"summary\": "...", \"score\": ìˆ«ì}}\'.
                        
                        - 90~100: ë¬¸ì¥ì— ì˜ê²¬ì´ ë“¤ì–´ê°€ì§€ ì•Šê³  ë¬¸ë²• ìƒ ì–´ìƒ‰í•¨ì´ ì—†ìœ¼ë©° í•µì‹¬ ì‚¬ì‹¤ì„ ì •í™•íˆ ìš”ì•½í•¨.
                        - 70~89: ëŒ€ì²´ë¡œ ì¢‹ìŒ (ì•½ê°„ì˜ ì–´ìƒ‰í•¨ì´ë‚˜ ë¶ˆëª…í™•í•œ ë¶€ë¶„ì´ ìˆì„ ìˆ˜ ìˆìŒ)
                        - 50~69: ë¶ˆì™„ì „ (í•µì‹¬ ëˆ„ë½ ë˜ëŠ” ë¬¸ë²•ì  ë¬¸ì œê°€ ì¡´ì¬í•¨)
                        - 0~49: ì‹¤íŒ¨ (ìš”ì•½ì´ ì›ë¬¸ê³¼ ê±°ì˜ ë¬´ê´€í•˜ê±°ë‚˜ ë¬¸ë²•ì´ ì‹¬ê°í•˜ê²Œ ì–´ìƒ‰í•¨)
                        """
                    ),
                    HumanMessagePromptTemplate.from_template(
                        "ì›ë¬¸:\n{input_text}\n\nìš”ì•½:\n{summary}"
                    ),
                ],
                input_variables=["input_text", "summary"],
            )

        runnable = eval_prompt | self.llm | SummaryScoreParser()
        try:
            result = runnable.invoke({
                "input_text": state["input_text"],
                "summary": state["summary"],
            })
            score = result["score"]
        except Exception as e:
            print(f"í‰ê°€ ì‹¤íŒ¨ ë°œìƒ: {e} â†’ score = 0 ìœ¼ë¡œ ì²˜ë¦¬í•˜ê³  ì¬ì‹œë„ ì˜ˆì •")
            score = 0  # ì—ëŸ¬ ë‚¬ìœ¼ë©´ ì‹¤íŒ¨ë¡œ ê°„ì£¼

        state["score"] = score
        return state

    def check_score(self, state: GraphState) -> str:
        """Scoreì— ë”°ë¼ ì„±ê³µ/ì¬ì‹œë„/ì‹¤íŒ¨ ë¶„ê¸°"""
        score = state["score"]
        retries = state.get("retry_count", 0)

        if int(score) >= 85:
            return "save"
        elif retries < self.max_retries:
            return "retry"
        else:
            return "log_fail"

    def retry_node(self, state: GraphState) -> GraphState:
        """âš™ï¸ ì¬ì‹œë„ ì‹œ íŒŒë¼ë¯¸í„° ì¡°ì •"""
        retry_count = state.get("retry_count", 0) + 1
        state["retry_count"] = retry_count
        return state

    def log_fail_node(self, state: GraphState) -> GraphState:
        """ğŸªµ ì‹¤íŒ¨ ê¸°ë¡ (í’ˆì§ˆ ë¬¸ì œ / ì‹œìŠ¤í…œ ì˜¤ë¥˜ íŒë‹¨)"""
        score = state.get("score", 0)
        if score < 50:
            state["fail_reason"] = "í’ˆì§ˆ ë¬¸ì œ"
        else:
            state["fail_reason"] = "ì‹œìŠ¤í…œ ì˜¤ë¥˜"
        return state

    def save_node(self, state: GraphState) -> GraphState:
        """ì„±ê³µí•œ ìš”ì•½ ì €ì¥"""
        state["status"] = "saved"
        return state

    def build(self):
        """LangGraph ì „ì²´ ì»´íŒŒì¼"""
        graph = StateGraph(GraphState)

        # ë…¸ë“œ ì¶”ê°€

        graph.add_node("summarize", self.summarize_node)
        graph.add_node("evaluate", self.evaluate_node)
        graph.add_node("retry", self.retry_node)
        graph.add_node("log_fail", self.log_fail_node)
        graph.add_node("save", self.save_node)

        # íë¦„ ì—°ê²°
        graph.add_edge(START, "summarize")
        graph.add_edge("summarize", "evaluate")
        graph.add_conditional_edges(
            "evaluate",
            self.check_score,
            {
                "save": "save",
                "retry": "retry",
                "log_fail": "log_fail",
            },
        )

        graph.add_edge("retry", "summarize")
        graph.add_edge("save", END)
        graph.add_edge("log_fail", END)

        return graph.compile()


examples = [
    HumanMessage(
        """
    ë„ë„ë“œ íŠ¸ëŸ¼í”„ ë¯¸êµ­ ëŒ€í†µë ¹ì€ ë°˜ë„ì²´ë¥¼ ë¹„ë¡¯í•œ ì „ìì œí’ˆì—ë„ ê´€ì„¸ë¥¼ ë¶€ê³¼í•˜ê² ë‹¤ëŠ” ì…ì¥ì„ ì¬í™•ì¸í•˜ë©° ê´€ì„¸ ì •ì±…ì— í›„í‡´ê°€ ì—†ìŒì„ ì‹œì‚¬í–ˆë‹¤.
    íŠ¸ëŸ¼í”„ ëŒ€í†µë ¹ì€ 13ì¼(í˜„ì§€ì‹œê°„) ìì‹ ì˜ ì‚¬íšŒê´€ê³„ë§ì„œë¹„ìŠ¤(SNS)ì— ì˜¬ë¦° ê¸€ì—ì„œ "ì§€ë‚œ ê¸ˆìš”ì¼(4ì›” 11ì¼)ì— ë°œí‘œí•œ ê²ƒì€ ê´€ì„¸ ì˜ˆì™¸(exception)ê°€ ì•„ë‹ˆë‹¤. ì´ë“¤ ì œí’ˆì€ ê¸°ì¡´ 20% íœíƒ€ë‹ ê´€ì„¸ë¥¼ ì ìš©ë°›ê³  ìˆìœ¼ë©° ë‹¨ì§€ ë‹¤ë¥¸ ê´€ì„¸ ë²”ì£¼(bucket)ë¡œ ì˜®ê¸°ëŠ” ê²ƒ"ì´ë¼ê³  ë°í˜”ë‹¤.
    ì´ì–´ "ìš°ë¦¬ëŠ” ë‹¤ê°€ì˜¤ëŠ” êµ­ê°€ ì•ˆë³´ ê´€ì„¸ ì¡°ì‚¬ì—ì„œ ë°˜ë„ì²´ì™€ ì „ìì œí’ˆ ê³µê¸‰ë§ ì „ì²´ë¥¼ ë“¤ì—¬ë‹¤ë³¼ ê²ƒ"ì´ë¼ê³  ë§í–ˆë‹¤.
    ì•ì„œ íŠ¸ëŸ¼í”„ ëŒ€í†µë ¹ì€ ì§€ë‚œ 11ì¼ ëŒ€í†µë ¹ ê°ì„œì—ì„œ ìƒí˜¸ê´€ì„¸ì—ì„œ ì œì™¸ë˜ëŠ” ë°˜ë„ì²´ ë“± ì „ìì œí’ˆ í’ˆëª©ì„ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œí–ˆê³ , ê´€ì„¸ ì§•ìˆ˜ë¥¼ ë‹´ë‹¹í•˜ëŠ” ì„¸ê´€êµ­ê²½ë³´í˜¸êµ­(CBP)ì´ ê°™ì€ ë‚  ì´ë¥¼ ê³µì§€í–ˆë‹¤.
    ì´ì— ë”°ë¼ ë°˜ë„ì²´ ë“± ì „ìì œí’ˆì€ ë¯¸êµ­ì´ ì¤‘êµ­ì— ë¶€ê³¼í•œ 125% ìƒí˜¸ê´€ì„¸, ê·¸ë¦¬ê³  í•œêµ­ì„ ë¹„ë¡¯í•œ ë‚˜ë¨¸ì§€ êµ­ê°€ì— ë¶€ê³¼í•œ ìƒí˜¸ê´€ì„¸(íŠ¸ëŸ¼í”„ ëŒ€í†µë ¹ì˜ ìœ ì˜ˆ ì¡°ì¹˜ë¡œ 7ì›” 8ì¼ê¹Œì§€ëŠ” 10% ê¸°ë³¸ê´€ì„¸ë§Œ ì ìš©)ë¥¼ ë‚´ì§€ ì•Šì•„ë„ ëœë‹¤.
    ë‹¤ë§Œ ë¯¸êµ­ì´ ë§ˆì•½ì„± ì§„í†µì œì¸ íœíƒ€ë‹ì˜ ë¯¸êµ­ ìœ ì… ì°¨ë‹¨ì— í˜‘ì¡°í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ì´ìœ ë¡œ ì¤‘êµ­ì— ë³„ë„ í–‰ì •ëª…ë ¹ì„ í†µí•´ ë¶€ê³¼í•œ 20% ê´€ì„¸ëŠ” ì—¬ì „íˆ ì ìš©ë°›ëŠ”ë‹¤.
    ì´ë¥¼ ë‘ê³  ë¯¸êµ­ ì–¸ë¡ ê³¼ ì—…ê³„ì—ì„œëŠ” íŠ¸ëŸ¼í”„ ëŒ€í†µë ¹ì´ ê°•ê²½ ê¸°ì¡°ì—ì„œ í•œë°œ ë¬¼ëŸ¬ë‚˜ ì „ìì œí’ˆì€ ì•„ì˜ˆ ê´€ì„¸ì—ì„œ ë©´ì œí•˜ëŠ” ê²Œ ì•„ë‹ˆëƒëŠ” ê´€ì¸¡ì´ ì œê¸°ëìœ¼ë©°, ë¯¼ì£¼ë‹¹ ë“±ì—ì„œëŠ” ì •ì±…ì— ì¼ê´€ì„±ì´ ì—†ë‹¤ê³  ë¹„íŒí–ˆë‹¤.
    ê·¸ëŸ¬ì ê´€ì„¸ë¥¼ ë‹´ë‹¹í•˜ëŠ” íŠ¸ëŸ¼í”„ í–‰ì •ë¶€ ë‹¹êµ­ìë“¤ì€ ì´ë‚  ë°©ì†¡ì— ì¶œì—°í•´ ë°˜ë„ì²´ ë“± ì „ìì œí’ˆì€ ì§€ë‚œ 2ì¼ ë°œí‘œí•œ êµ­ê°€ë³„ ìƒí˜¸ê´€ì„¸ì—ì„œ ì œì™¸ë  ë¿ ì•ìœ¼ë¡œ ì§„í–‰í•  'ë¬´ì—­í™•ì¥ë²• 232ì¡°' ì¡°ì‚¬ë¥¼ í†µí•´ ê´€ì„¸ë¥¼ ë¶€ê³¼í•  ë°©ì¹¨ì´ë¼ê³  ì„¤ëª…í–ˆë‹¤.
    ë°˜ë„ì²´ ë“± êµ­ê°€ ì•ˆë³´ì— ì¤‘ìš”í•œ í’ˆëª©ì€ ì•ì„œ 25% ê´€ì„¸ë¥¼ ë¶€ê³¼í•œ ì² ê°•ì´ë‚˜ ìë™ì°¨ì™€ ë§ˆì°¬ê°€ì§€ë¡œ ìƒí˜¸ê´€ì„¸ì™€ ì¤‘ì²©ë˜ì§€ ì•ŠëŠ” í’ˆëª©ë³„ ê´€ì„¸ë¥¼ ë¶€ê³¼í•˜ê² ë‹¤ëŠ” ê²ƒì´ë‹¤.
    íŠ¸ëŸ¼í”„ ëŒ€í†µë ¹ë„ ì´ë‚  ê´€ì„¸ ê°•í–‰ ì˜ì§€ë¥¼ í”¼ë ¥í–ˆë‹¤.
    ê·¸ëŠ” "ë‹¤ë¥¸ ë‚˜ë¼ë“¤ì´ ìš°ë¦¬ë¥¼ ìƒëŒ€ë¡œ ì´ìš©í•œ ë¹„(é)ê¸ˆì „ì  ê´€ì„¸ ì¥ë²½ ë° ë¶ˆê³µì •í•œ ë¬´ì—­ìˆ˜ì§€ì™€ ê´€ë ¨í•´ ëˆ„êµ¬ë„ ë´ì£¼ì§€ ì•Šê² ë‹¤(Nobody is getting off the hook). 
    íŠ¹íˆ ìš°ë¦¬ë¥¼ ìµœì•…ìœ¼ë¡œ ëŒ€ìš°í•˜ëŠ” ì¤‘êµ­ì€ ë´ì£¼ì§€ ì•Šê² ë‹¤"ê³  ë°í˜”ë‹¤.
    íŠ¸ëŸ¼í”„ ëŒ€í†µë ¹ì€ "ìš°ë¦¬ëŠ” ì œí’ˆì„ ë¯¸êµ­ì—ì„œ ë§Œë“¤ì–´ì•¼ í•˜ë©° ìš°ë¦¬ëŠ” ë‹¤ë¥¸ ë‚˜ë¼ì— ì¸ì§ˆë¡œ ì¡íˆì§€ ì•Šì„ ê²ƒì´ë‹¤. íŠ¹íˆ ì¤‘êµ­ê°™ì´ ë¯¸êµ­ë¯¼ì„ ë¬´ì‹œí•˜ê¸° ìœ„í•´ ê°€ì§„ ëª¨ë“  ê¶Œë ¥ì„ ì´ìš©í•  ì ëŒ€ì ì¸ êµì—­êµ­ì— ëŒ€í•´ ê·¸ë ‡ë‹¤"ë¼ê³  ê°•ì¡°í–ˆë‹¤.
    """
    ),
    AIMessage(
        dedent(
            """

            íŠ¸ëŸ¼í”„ ëŒ€í†µë ¹ì€ ê´€ì„¸ ì •ì±…ì— ë³€í™”ê°€ ì—†ìŒì„ ì¬í™•ì¸í•˜ë©°, ë°˜ë„ì²´ ë° ì „ìì œí’ˆì— ëŒ€í•œ ê¸°ì¡´ 20% íœíƒ€ë‹ ê´€ì„¸ë¥¼ ìœ ì§€í•˜ê³  êµ­ê°€ ì•ˆë³´ ì¡°ì‚¬ ì‹œ ë°˜ë„ì²´ì™€ ì „ìì œí’ˆ ê³µê¸‰ë§ì„ ê²€í† í•  ê²ƒì„ì„ ë°œí‘œí•˜ì˜€ìŠµë‹ˆë‹¤. 
            ì´ëŠ” ì¤‘êµ­ì— ë¶€ê³¼ëœ ìƒí˜¸ê´€ì„¸ì˜ ì¼ë¶€ ë©´ì œì—ë„ ë¶ˆêµ¬í•œ ì¡°ì¹˜ì…ë‹ˆë‹¤. 
            íŠ¸ëŸ¼í”„ ëŒ€í†µë ¹ì€ ëª¨ë“  êµ­ê°€, íŠ¹íˆ ë¯¸êµ­ì„ ìµœì•…ìœ¼ë¡œ ëŒ€ìš°í•˜ëŠ” ì¤‘êµ­ì— ëŒ€í•´ ê´€ì„¸ ì •ì±…ì„ ê³„ì† ì¶”ì§„í•  ê²ƒì„ì„ ê°•ì¡°í–ˆìŠµë‹ˆë‹¤.
            """
        )
    ),
]


class SummarizationRunner:
    """URL ë¦¬ìŠ¤íŠ¸ë¥¼ ì…ë ¥ ë°›ì•„ ë³‘ë ¬ë¡œ ìš”ì•½/í‰ê°€í•˜ëŠ” ì‹¤í–‰ í´ë˜ìŠ¤"""

    def __init__(self, urls: List[str], server: str, model: str, max_workers: int = 6):
        self.urls = urls
        self.max_workers = max_workers
        self.graph = SummarizationGraph(server, model, examples=examples).build()

    def prepare_texts(self) -> List[Tuple[str, str]]:
        return ArticleExtractor.extract(self.urls, max_workers=self.max_workers)

    def run_graph(self, text: str, worker_id: int) -> GraphState:
        return self.graph.invoke({"input_text": text, "worker_id": worker_id})

    def parallel_run(self, pairs: List[Tuple[str, str]]):
        results = []
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = [
                executor.submit(self.run_graph, text, idx)
                for idx, (url, text) in enumerate(pairs)
            ]
            for idx, future in enumerate(as_completed(futures), 1):
                try:
                    result = future.result()
                    results.append(result)
                    print(f"âœ… {idx}/{len(pairs)} ì™„ë£Œ | ì ìˆ˜: {result['score']}")
                except Exception as e:
                    print(f"âŒ {idx}/{len(pairs)} ì‹¤íŒ¨: {e}")
        return results

    def run(self):
        start = time.time()
        pairs = self.prepare_texts()
        print(f"ğŸ” ì¶”ì¶œ ì™„ë£Œ. {len(pairs)}ê°œ ê¸°ì‚¬ ìš”ì•½ ì‹œì‘!")
        results = self.parallel_run(pairs)
        print("\nğŸ¯ ì „ì²´ ì™„ë£Œ!")
        for i, res in enumerate(results, 1):
            print(f"\nğŸ“ ìš”ì•½ {i}")
            print(json.dumps(res, indent=2, ensure_ascii=False))
        print(f"\nâ±ï¸ ì´ ì†Œìš” ì‹œê°„: {time.time() - start:.2f}s")


# ğŸ”§ ë©”ì¸ í•¨ìˆ˜
def main():
    URLS = [
        "https://www.hani.co.kr/arti/society/society_general/1192251.html",
        "https://www.hani.co.kr/arti/society/society_general/1192255.html",
        "https://www.hankyung.com/article/2025041493977",
        "https://www.khan.co.kr/article/202504141136001",
        "https://www.mk.co.kr/news/politics/11290687",
        "https://www.chosun.com/politics/politics_general/2025/04/14/THWVKUHQG5CKFJF6CLZLP5PKM4",
    ]
    SERVER = "https://4e45-34-87-129-244.ngrok-free.app"
    MODEL = "naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-0.5B"

    runner = SummarizationRunner(URLS, SERVER, MODEL)
    runner.run()


if __name__ == "__main__":
    main()
