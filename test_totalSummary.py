import logging
import time
from pprint import pprint

from ai_models.runner import Runner
from scrapers.article_extractor import ArticleExtractor
from ai_models.graph.total_summary import TotalSummarizationGraph
from ai_models.graph.Summary import SummarizationGraph
import dotenv


# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[logging.StreamHandler()],
)


def test_summary_graph():
    URLS = [
        "https://www.hani.co.kr/arti/society/society_general/1192251.html",
        "https://www.hani.co.kr/arti/society/society_general/1192255.html",
        "https://www.hankyung.com/article/2025041493977",
        "https://www.khan.co.kr/article/202504141136001",
        "https://www.mk.co.kr/news/politics/11290687",
        "https://www.chosun.com/politics/politics_general/2025/04/14/THWVKUHQG5CKFJF6CLZLP5PKM4",
    ]
    SERVER = "https://5a09-34-125-119-95.ngrok-free.app"
    MODEL = "naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B"

    logging.info("ğŸ“¦ ëª¨ë¸ ë° ê·¸ë˜í”„ ì´ˆê¸°í™” ì¤‘...")
    graph = SummarizationGraph(SERVER, MODEL).build()
    graph_total = TotalSummarizationGraph(SERVER, MODEL).build()

    logging.info("ğŸ“° ê¸°ì‚¬ ë³¸ë¬¸ ì¶”ì¶œ ì‹œì‘...")
    extractor = ArticleExtractor()
    start_time = time.time()
    try:
        articles = extractor.search(urls=URLS)
        logging.info(articles)
    except Exception as e:
        logging.exception("âŒ ê¸°ì‚¬ ì¶”ì¶œ ì‹¤íŒ¨:")
        return
    logging.info(
        f"âœ… {len(articles)}ê°œ ê¸°ì‚¬ ë³¸ë¬¸ ì¶”ì¶œ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {time.time() - start_time:.2f}s)"
    )

    logging.info("ğŸ“„ 1ì°¨ ìš”ì•½(ê°œë³„ ê¸°ì‚¬) ì‹œì‘...")
    runner = Runner(graph=graph)
    first_results = runner.run(texts=articles)
    for i, res in enumerate(first_results):
        logging.info(f"ğŸ“ [1ì°¨ ì œëª© {i+1}] {articles[i]['title']}")
        logging.info(f"ğŸ“ [1ì°¨ ê²°ê³¼ {i+1}] {res['text'][:60]}...")
        logging.info(f"ğŸ“ [1ì°¨ ë³¸ë¬¸ {i+1}] {res['input_text'][:60]}...")

    summarized_texts = [r["text"] for r in first_results]
    summarized_texts = {"text": "\n\n".join(summarized_texts)}

    logging.info("ğŸ“š 2ì°¨ ìš”ì•½(í†µí•© ìš”ì•½) ì‹œì‘...")
    final_runner = Runner(graph=graph_total)
    final_results = final_runner.run(texts=[summarized_texts])

    logging.info("âœ… ìµœì¢… í†µí•© ìš”ì•½ ê²°ê³¼:")
    pprint(final_results)


if __name__ == "__main__":
    dotenv.load_dotenv(override=True)
    test_summary_graph()
